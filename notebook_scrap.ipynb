{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "from time import sleep\n",
    "from timeit import default_timer\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from neuralforecast.auto import (\n",
    "    AutoRNN,\n",
    "    AutoLSTM,\n",
    "    AutoGRU,\n",
    "    AutoTCN,\n",
    "    AutoDeepAR,\n",
    "    AutoDilatedRNN,\n",
    "    AutoMLP,\n",
    "    AutoNBEATS,\n",
    "    AutoNBEATSx,\n",
    "    AutoNHITS,\n",
    "    AutoTFT,\n",
    "    AutoVanillaTransformer,\n",
    "    AutoInformer,\n",
    "    AutoAutoformer,\n",
    "    AutoFEDformer,\n",
    "    AutoPatchTST,\n",
    "    AutoTimesNet,\n",
    "    AutoStemGNN,\n",
    "    AutoHINT,\n",
    ")\n",
    "from statsforecast.models import (\n",
    "    HistoricAverage,\n",
    "    Naive,\n",
    "    RandomWalkWithDrift,\n",
    "    SeasonalNaive,\n",
    "    WindowAverage,\n",
    "    SeasonalWindowAverage,\n",
    "    ADIDA,\n",
    "    CrostonClassic,\n",
    "    CrostonSBA,\n",
    "    IMAPA,\n",
    "    TSB,\n",
    "    Theta,\n",
    "    AutoARIMA,\n",
    "    OptimizedTheta,\n",
    "    AutoCES,\n",
    "    AutoETS,\n",
    "    DynamicTheta,\n",
    "    SimpleExponentialSmoothing,\n",
    "    SimpleExponentialSmoothingOptimized,\n",
    "    SeasonalExponentialSmoothing,\n",
    "    SeasonalExponentialSmoothingOptimized,\n",
    "    Holt,\n",
    "    HoltWinters,\n",
    ")\n",
    "\n",
    "baseline_model_dict = {\n",
    "    \"historic_average_baseline\": HistoricAverage,\n",
    "    \"naive_baseline\": Naive,\n",
    "    \"random_walk_baseline\": RandomWalkWithDrift,\n",
    "    # \"window_average_baseline\": WindowAverage,\n",
    "}\n",
    "\n",
    "seasonal_baseline_model_dict = {\n",
    "    \"seasonal_naive_baseline\": SeasonalNaive,\n",
    "    # \"seasonal_window_average_baseline\": SeasonalWindowAverage,\n",
    "}\n",
    "\n",
    "model_dict = {\n",
    "    # 'adida_model':ADIDA,\n",
    "    # 'croston_classic_model':CrostonClassic,\n",
    "    # 'croston_sba_model':CrostonSBA,\n",
    "    # 'imapa_model':IMAPA,\n",
    "    # 'tsb_model':TSB,\n",
    "    'theta_model': Theta,\n",
    "    'auto_arima_model':AutoARIMA,\n",
    "    'optimized_theta_model': OptimizedTheta,\n",
    "    'auto_ces_model': AutoCES,\n",
    "    'auto_ets_model': AutoETS,\n",
    "    'dynamic_theta_model': DynamicTheta,\n",
    "    # 'simple_exponential_smoothing_model':SimpleExponentialSmoothing,\n",
    "    'simple_exponential_smoothing_optimized_model': SimpleExponentialSmoothingOptimized,\n",
    "    # 'seasonal_exponential_smoothing_model':SeasonalExponentialSmoothing,\n",
    "    'seasonal_exponential_smoothing_optimized_model': SeasonalExponentialSmoothingOptimized,\n",
    "    'holt_model': Holt,\n",
    "    'holt_winters_model': HoltWinters,\n",
    "}\n",
    "\n",
    "model_list = {\n",
    "    # 'AutoRNN':AutoRNN,\n",
    "    # 'AutoStemGNN':AutoStemGNN,\n",
    "    # 'AutoHINT':AutoHINT,\n",
    "    'AutoLSTM':AutoLSTM,\n",
    "    'AutoGRU':AutoGRU,\n",
    "    'AutoTCN':AutoTCN,\n",
    "    # 'AutoDeepAR': AutoDeepAR,\n",
    "    'AutoDilatedRNN':AutoDilatedRNN,\n",
    "    'AutoMLP':AutoMLP,\n",
    "    'AutoNBEATS':AutoNBEATS,\n",
    "    'AutoNBEATSx':AutoNBEATSx,\n",
    "    'AutoNHITS':AutoNHITS,\n",
    "    # 'AutoTFT':AutoTFT,\n",
    "    # 'AutoVanillaTransformer':AutoVanillaTransformer,\n",
    "    # 'AutoInformer':AutoInformer,\n",
    "    # 'AutoAutoformer':AutoAutoformer,\n",
    "    # 'AutoFEDformer':AutoFEDformer,\n",
    "    # 'AutoPatchTST':AutoPatchTST,\n",
    "    # 'AutoTimesNet':AutoTimesNet,\n",
    "}\n",
    "\n",
    "def run_auto_deep_learning(model_list, forecast_horizon, new_uni_data):\n",
    "    \n",
    "    all_forecasts = {}\n",
    "    all_metrics = {}\n",
    "\n",
    "    for model_name, model in model_list.items():\n",
    "\n",
    "        print(str(model_name))\n",
    "        try:\n",
    "\n",
    "            start = default_timer()\n",
    "            models = [model(h=forecast_horizon, backend='ray', num_samples=2, loss=MAE())]\n",
    "\n",
    "            nf = NeuralForecast(models=models, freq='D')\n",
    "            nf.fit(df=new_uni_data[:-forecast_horizon])\n",
    "\n",
    "            Y_hat_df = nf.predict()\n",
    "            Y_hat_df = Y_hat_df.reset_index()\n",
    "\n",
    "            Y_hat_df['actual'] = new_uni_data[-forecast_horizon:]['y'].values\n",
    "\n",
    "            all_forecasts[model_name] = Y_hat_df\n",
    "\n",
    "            single_metric = get_metrics(Y_hat_df, model_name, 'actual')\n",
    "\n",
    "            single_metric['time_taken'] = round(default_timer() - start, 3)\n",
    "\n",
    "            all_metrics[model_name] = single_metric\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(e)\n",
    "            print(f'Failed {model_name}')\n",
    "            results = pd.DataFrame([e])\n",
    "            results.to_csv(f'{model_name}.csv')\n",
    "            continue\n",
    "        \n",
    "    return pd.DataFrame(all_metrics).T, pd.DataFrame([all_forecasts]).T\n",
    "\n",
    "\n",
    "\n",
    "def get_metrics(prediction_dataframe, prediction_column, actual_column):\n",
    "\n",
    "    e = prediction_dataframe[prediction_column].values - \\\n",
    "        prediction_dataframe[actual_column].values\n",
    "\n",
    "    ae, se, pe = abs(e), e**2, (e/prediction_dataframe[actual_column].values)\n",
    "\n",
    "    mae, mse, mpe, ape = mean(ae), mean(se), mean(\n",
    "        pe), (ae/prediction_dataframe[actual_column].values)\n",
    "\n",
    "    rmse, mape = mse**0.5, mean(ape)\n",
    "    \n",
    "    wide_mape = round(abs(prediction_dataframe[prediction_column].sum() - prediction_dataframe[actual_column].sum())/prediction_dataframe[actual_column].sum(),4)\n",
    "    \n",
    "    return {'mae': mae, 'mse': mse, 'mpe': mpe, 'rmse': rmse, 'mape': mape, 'wide_mape':wide_mape}\n",
    "\n",
    "\n",
    "def get_model_predictions(model_dict, univariant_data, train_data, actual_values, forecast_horizon, seasonal):\n",
    "\n",
    "    model_result = {}\n",
    "    model_predictions = {}\n",
    "    model_inpredictions = {}\n",
    "\n",
    "    for model_name, model in model_dict.items():\n",
    "        try:\n",
    "            print(model_name)\n",
    "\n",
    "            try:\n",
    "                intmodel = model(season_length=seasonal)\n",
    "            except:\n",
    "                intmodel = model()\n",
    "\n",
    "            fitted_model = intmodel.forecast(\n",
    "                y=train_data, fitted=True, h=forecast_horizon)\n",
    "\n",
    "            mean_prediction = fitted_model['mean']\n",
    "\n",
    "            insample_prediction = fitted_model['fitted']\n",
    "            insample_prediction[np.isnan(insample_prediction)] = 0\n",
    "\n",
    "            prediction_dataframe = pd.DataFrame(\n",
    "                mean_prediction, actual_values).reset_index()\n",
    "            prediction_dataframe.columns = [\"actual\", \"prediction\"]\n",
    "\n",
    "            model_result[model_name] = get_metrics(\n",
    "                prediction_dataframe, 'prediction', 'actual')\n",
    "            model_predictions[model_name] = mean_prediction\n",
    "            model_inpredictions[model_name] = insample_prediction\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(model_predictions)\n",
    "\n",
    "    model_predictions_df = pd.DataFrame(\n",
    "        model_predictions, index=univariant_data.index[-forecast_horizon:]).fillna(0)\n",
    "    model_result_df = pd.DataFrame(model_result).fillna(0)\n",
    "    model_inpredictions_df = pd.DataFrame(\n",
    "        model_inpredictions, univariant_data.index[:-forecast_horizon]).fillna(0)\n",
    "\n",
    "    return model_predictions_df, model_inpredictions_df, model_result_df\n",
    "\n",
    "\n",
    "def get_baseline_forecasts(baseline_model_dict, seasonal_baseline_model_dict, model_dict, univariant_data, train_data, actual_values, forecast_horizon, seasonal, window):\n",
    "\n",
    "    baseline_result = {}\n",
    "    baseline_predictions = {}\n",
    "    baseline_inpredictions = {}\n",
    "\n",
    "    for model_name, model in baseline_model_dict.items():\n",
    "\n",
    "        print(model_name)\n",
    "\n",
    "        if 'window' in model_name:\n",
    "            intmodel = model(window_size=window)\n",
    "\n",
    "        else:\n",
    "            intmodel = model()\n",
    "\n",
    "        fitted_model = intmodel.forecast(\n",
    "            y=train_data, fitted=True, h=forecast_horizon)\n",
    "\n",
    "        mean_prediction = fitted_model['mean']\n",
    "        insample_prediction = fitted_model['fitted']\n",
    "\n",
    "        prediction_dataframe = pd.DataFrame(\n",
    "            mean_prediction, actual_values).reset_index()\n",
    "        prediction_dataframe.columns = [\"actual\", \"prediction\"]\n",
    "\n",
    "        baseline_result[model_name] = get_metrics(\n",
    "            prediction_dataframe, 'prediction', 'actual')\n",
    "\n",
    "        baseline_predictions[model_name] = mean_prediction\n",
    "        baseline_inpredictions[model_name] = insample_prediction\n",
    "\n",
    "    for model_name, model in seasonal_baseline_model_dict.items():\n",
    "        print(model_name)\n",
    "\n",
    "        if 'window' in model_name:\n",
    "            intmodel = model(season_length=seasonal, window_size=1)\n",
    "\n",
    "        else:\n",
    "            intmodel = model(season_length=seasonal)\n",
    "\n",
    "        fitted_model = intmodel.forecast(\n",
    "            y=train_data, fitted=True, h=forecast_horizon)\n",
    "\n",
    "        mean_prediction = fitted_model['mean']\n",
    "\n",
    "        insample_prediction = fitted_model['fitted']\n",
    "        insample_prediction[np.isnan(insample_prediction)] = 0\n",
    "\n",
    "        prediction_dataframe = pd.DataFrame(\n",
    "            mean_prediction, actual_values).reset_index()\n",
    "        prediction_dataframe.columns = [\"actual\", \"prediction\"]\n",
    "\n",
    "        baseline_result[model_name] = get_metrics(\n",
    "            prediction_dataframe, 'prediction', 'actual')\n",
    "        baseline_predictions[model_name] = mean_prediction\n",
    "        baseline_inpredictions[model_name] = insample_prediction\n",
    "\n",
    "    baseline_predictions['actual'] = actual_values\n",
    "    baseline_inpredictions['actual'] = train_data\n",
    "\n",
    "    baseline_predictions_df = pd.DataFrame(\n",
    "        baseline_predictions, index=univariant_data.index[-forecast_horizon:]).fillna(0)\n",
    "    baseline_result_df = pd.DataFrame(baseline_result).fillna(0)\n",
    "    baseline_inpredictions_df = pd.DataFrame(\n",
    "        baseline_inpredictions, univariant_data.index[:-forecast_horizon]).fillna(0)\n",
    "    \n",
    "    return baseline_predictions_df, baseline_inpredictions_df, baseline_result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}\n",
    "final_forecast = {}\n",
    "\n",
    "# raw_sales_data = pd.read_csv(\n",
    "#     'gs://gfk-eco-local-forecast/simulations/neo_backtest_regular/Weekly/2780/backtests/raw_sales_data.csv')\n",
    "\n",
    "raw_sales_data = pd.read_csv('sales_data.csv').drop(columns=['Unnamed: 0'])\n",
    "\n",
    "all_cell_rows = ['-'.join(value) for value in raw_sales_data[['country_code', 'item_group_code', 'outlet_group_code']].values]\n",
    "\n",
    "raw_sales_data['cell'] = all_cell_rows\n",
    "\n",
    "for cell in set(all_cell_rows):\n",
    "\n",
    "    full_data = raw_sales_data[raw_sales_data['cell']==cell].sort_values(by='period_seq').set_index(\"start_date\")\n",
    "\n",
    "    full_data.index = pd.to_datetime(full_data.index, format=\"%Y-%m-%d\")\n",
    "\n",
    "    single_column = \"quantity\"\n",
    "\n",
    "    univariant_data = full_data[[single_column]]\n",
    "\n",
    "    if univariant_data.shape[0] < 80:\n",
    "        continue\n",
    "\n",
    "    univariant_data = univariant_data\n",
    "    univariant_data[single_column] = univariant_data[single_column].astype(float)\n",
    "\n",
    "    forecast_horizon = 12\n",
    "\n",
    "    window = 6\n",
    "    seasonal = 12\n",
    "\n",
    "    actual_values = np.array([value[0] for value in univariant_data.values[-forecast_horizon:]])\n",
    "    train_data = np.array([value[0] for value in univariant_data.values[:-forecast_horizon]])\n",
    "\n",
    "    model_predictions_df, model_inpredictions_df, model_result_df = get_model_predictions(model_dict, univariant_data, train_data, actual_values, forecast_horizon, seasonal)\n",
    "\n",
    "    baseline_predictions_df, baseline_inpredictions_df, baseline_result_df = get_baseline_forecasts(baseline_model_dict, seasonal_baseline_model_dict, model_dict, univariant_data, train_data, actual_values, forecast_horizon, seasonal, window)\n",
    "\n",
    "    all_results = pd.concat([model_result_df, baseline_result_df], axis=1).T.sort_values(by=['mpe'])\n",
    "\n",
    "    all_predictions = pd.concat([baseline_predictions_df, model_predictions_df], axis=1)\n",
    "\n",
    "    all_inpredictions = pd.concat([baseline_inpredictions_df, model_inpredictions_df], axis=1)\n",
    "    \n",
    "    \n",
    "    testing_4 = all_predictions.T.mean().values\n",
    "    \n",
    "    testing_5 = all_predictions.T.median().values\n",
    "    \n",
    "    model_1 = xgb.XGBRegressor()\n",
    "    model_2 = lgb.LGBMRegressor()\n",
    "\n",
    "    good_models = all_results.sort_values(by='rmse').index.tolist()\n",
    "\n",
    "    model_1.fit(all_inpredictions[good_models], all_inpredictions['actual'])\n",
    "\n",
    "    model_2.fit(all_inpredictions[good_models], all_inpredictions['actual'])\n",
    "\n",
    "    testing_1 = pd.DataFrame(list(model_1.predict(all_predictions[good_models])),all_predictions['actual'].to_list()).reset_index()\n",
    "\n",
    "    testing_2 = pd.DataFrame(list(model_2.predict(all_predictions[good_models])),all_predictions['actual'].to_list()).reset_index()\n",
    "    \n",
    "    testing_3 = pd.DataFrame(testing_1['index'].values, pd.concat([testing_1, testing_2], axis=1).drop(columns=['index']).T.mean().values).reset_index()\n",
    "    \n",
    "    testing_4 = pd.DataFrame(testing_4,all_predictions['actual'].to_list()).reset_index()\n",
    "    \n",
    "    testing_5 = pd.DataFrame(testing_5, all_predictions['actual'].to_list()).reset_index()\n",
    "\n",
    "    xgboost_result = pd.DataFrame([get_metrics(testing_1, 0, 'index')])\n",
    "    xgboost_result = xgboost_result.T.rename(columns={0:'xgboost'}).T\n",
    "\n",
    "    lightgbm_result = pd.DataFrame([get_metrics(testing_2, 0, 'index')])\n",
    "    lightgbm_result = lightgbm_result.T.rename(columns={0:'lightgbm'}).T\n",
    "\n",
    "    lgb_xgb_result = pd.DataFrame([get_metrics(testing_3, 0, 'index')])\n",
    "    lgb_xgb_result = lgb_xgb_result.T.rename(columns={0:'lightgbm-xgboost'}).T\n",
    "    \n",
    "    mean_ensemble = pd.DataFrame([get_metrics(testing_4, 0, 'index')])\n",
    "    mean_ensemble = mean_ensemble.T.rename(columns={0:'mean_ensemble'}).T\n",
    "    \n",
    "    median_ensemble = pd.DataFrame([get_metrics(testing_5, 0, 'index')])\n",
    "    median_ensemble = median_ensemble.T.rename(columns={0:'median_ensemble'}).T\n",
    "    \n",
    "    testing_3.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    all_results  = pd.concat([all_results, xgboost_result, lightgbm_result, lgb_xgb_result, mean_ensemble, median_ensemble]).sort_values(by='rmse')\n",
    "    \n",
    "    \n",
    "    all_predictions['lightgbm'] = testing_1[0].values\n",
    "    all_predictions['xgboost'] = testing_2[0].values\n",
    "    all_predictions['lightgbm-xgboost'] = testing_3[0].values\n",
    "    \n",
    "    new_uni_data = univariant_data.reset_index().rename(columns={'start_date':'ds', single_column:'y'}).head(1800)\n",
    "    new_uni_data['unique_id'] = 1.0\n",
    "    \n",
    "    deep_results, deep_forecasts = run_auto_deep_learning(model_list, forecast_horizon, new_uni_data)\n",
    "\n",
    "    all_results = pd.concat([all_results, deep_results])\n",
    "    \n",
    "    all_predictions = pd.concat([all_predictions, deep_forecasts])\n",
    "\n",
    "    final_results[cell] = all_results\n",
    "    \n",
    "    final_forecast[cell] = all_predictions\n",
    "    \n",
    "    metric_file_path = \"metrics.pkl\"\n",
    "    \n",
    "    forecast_file_path = \"forecast.pkl\"\n",
    "\n",
    "    with open(metric_file_path, \"wb\") as pkl_file:\n",
    "        pickle.dump(final_results, pkl_file)\n",
    "        \n",
    "    with open(forecast_file_path, \"wb\") as pkl_file:\n",
    "        pickle.dump(final_forecast, pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([all_results, deep_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "fypyseries",
   "name": "common-cpu.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m111"
  },
  "kernelspec": {
   "display_name": "fypyseries",
   "language": "python",
   "name": "fypyseries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c984af145c51368d9341d2564c072ccce228d05aac5ccfd4f9ed9007394b289"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
